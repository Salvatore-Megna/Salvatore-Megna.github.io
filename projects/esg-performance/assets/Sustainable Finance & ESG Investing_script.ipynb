{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd5ea9c-8240-4c80-8438-e158e2351dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "ANALISI ESG ENERGY — avvio (Layer A 12M → Layer B)\n",
      "==============================================================================\n",
      ">>> Controllo duplicati su date di r_titoli: 0\n",
      "\n",
      ">>> Anteprima PANEL (senza r_rel):\n",
      "      date  ticker area   periodo esg_class    E_lag1    S_lag1    G_lag1  ESG_lag1\n",
      "2013-02-28    BP.L   EU pre_trump       Low 35.858662 33.591288 32.297575 34.039327\n",
      "2013-02-28     CVX  USA pre_trump       Low 48.812464 42.392669 34.117823 41.860691\n",
      "2013-02-28     DUK  USA pre_trump      High 67.009163 44.420507 44.554772 64.186761\n",
      "2013-02-28 ENEL.MI   EU pre_trump      High 77.691854 45.629006 36.938903 72.563546\n",
      "2013-02-28  ENI.MI   EU pre_trump       Low 76.225094 29.708024 29.087768 35.850078\n",
      "\n",
      "Tickers nel panel: ['BP.L', 'CVX', 'DUK', 'ENEL.MI', 'ENI.MI', 'EOAN.DE', 'IBE.MC', 'NEE', 'OXY', 'TTE.PA', 'XEL', 'XOM']\n",
      "Date: 2013-02-28 → 2024-12-31\n",
      "\n",
      "Distribuzione osservazioni (periodo → area → classe):\n",
      "  periodo area esg_class  n_osservazioni\n",
      "pre_trump   EU      High             141\n",
      "pre_trump   EU       Low             141\n",
      "pre_trump  USA      High             141\n",
      "pre_trump  USA       Low             141\n",
      "    trump   EU      High             144\n",
      "    trump   EU       Low             144\n",
      "    trump  USA      High             144\n",
      "    trump  USA       Low             144\n",
      "    biden   EU      High             144\n",
      "    biden   EU       Low             144\n",
      "    biden  USA      High             144\n",
      "    biden  USA       Low             144\n",
      "\n",
      "=== TARGET 12M — Check (senza r_rel) ===\n",
      "ticker       date  r_rel_12m_fwd    E_lag1    S_lag1    G_lag1  ESG_lag1   periodo area esg_class\n",
      "  BP.L 2013-02-28       0.025582 35.858662 33.591288 32.297575 34.039327 pre_trump   EU       Low\n",
      "  BP.L 2013-03-31      -0.036055 34.977829 33.659781 31.681334 33.370163 pre_trump   EU       Low\n",
      "  BP.L 2013-04-30      -0.084406 35.166104 34.113456 32.035995 33.646384 pre_trump   EU       Low\n",
      "  BP.L 2013-05-31      -0.079388 36.638062 36.138937 32.520517 34.742047 pre_trump   EU       Low\n",
      "  BP.L 2013-06-30      -0.109449 36.639277 36.216459 32.341308 34.619913 pre_trump   EU       Low\n",
      "\n",
      "=== LAYER A (12M avanti) — METRICHE TEST (periodo → area) ===\n",
      "  periodo area  R2_test  MAE_test  n_total  n_train  n_test\n",
      "pre_trump   EU   -1.399     0.123      282      225      57\n",
      "pre_trump  USA   -0.475     0.132      282      225      57\n",
      "    trump   EU   -1.813     0.278      288      230      58\n",
      "    trump  USA   -0.395     0.309      288      230      58\n",
      "    biden   EU   -1.071     0.163      216      172      44\n",
      "    biden  USA   -1.387     0.201      216      172      44\n",
      "\n",
      "=== SHARPE RELATIVO — AGGREGATO per GRUPPO (periodo → area × classe) ===\n",
      "  periodo area esg_class  sharpe_agg   mean   std  n\n",
      "pre_trump   EU      High       0.152  0.003 0.057 47\n",
      "pre_trump   EU       Low       0.112  0.001 0.029 47\n",
      "pre_trump  USA      High       0.431  0.009 0.072 47\n",
      "pre_trump  USA       Low       0.094  0.001 0.025 47\n",
      "    trump   EU      High       0.894  0.017 0.065 48\n",
      "    trump   EU       Low      -0.782 -0.005 0.020 48\n",
      "    trump  USA      High       0.668  0.020 0.104 48\n",
      "    trump  USA       Low       0.042  0.000 0.039 48\n",
      "    biden   EU      High      -0.224 -0.004 0.066 48\n",
      "    biden   EU       Low       0.397  0.003 0.028 48\n",
      "    biden  USA      High      -0.667 -0.018 0.095 48\n",
      "    biden  USA       Low       0.098  0.001 0.029 48\n",
      "\n",
      "=== TEST BOOTSTRAP: Delta Sharpe (High - Low) (periodo → area) ===\n",
      "  periodo area  delta_sharpe_high_minus_low  ci95_low  ci95_high  p_value  n_months\n",
      "pre_trump   EU                        0.040    -0.918      0.989    0.930        47\n",
      "pre_trump  USA                        0.337    -0.612      1.387    0.588        47\n",
      "    trump   EU                        1.676     0.371      3.223    0.530        48\n",
      "    trump  USA                        0.626    -0.807      2.447    0.576        48\n",
      "    biden   EU                       -0.622    -2.101      0.848    0.556        48\n",
      "    biden  USA                       -0.765    -2.039      0.729    0.513        48\n",
      "\n",
      "FINE.\n"
     ]
    }
   ],
   "source": [
    "#Analisi ESG su aziende Energy (USA/EU)\n",
    "\n",
    "#Layer A: test di predittività -> Random Forest sui rendimenti relativi a 12 mesi (target in avanti).\n",
    "#Layer B: outcome -> Sharpe ratio relativo per gruppi (High vs Low ESG), per periodo e area.\n",
    "\n",
    "#NOTE:\n",
    "# Usiamo benchmark settoriali da file (USA≈XLE; EU≈EXH1.DE) già in termini di rendimenti mensili.\n",
    "#-Rimuoviamo i duplicati mensili sui prezzi (se ci sono più righe nello stesso mese, teniamo l’ultima).\n",
    "#Periodi ordinati: pre_trump (2013–2016), trump (2017–2020), biden (2021–2024).\n",
    "\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "# PERCORSI FILE \n",
    "\n",
    "PRICES_CSV     = r\"C:\\Users\\totim\\OneDrive\\Desktop\\prezzi_mensili_aggiornato.csv\"     # prezzi mensili (date,ticker,price)\n",
    "BENCH_CSV      = r\"C:\\Users\\totim\\OneDrive\\Desktop\\benchmarks_monthly_returns.csv\"    # rendimenti benchmark (date,bm_USA,bm_EU)\n",
    "ESG_PANEL_XLSX = r\"C:\\Users\\totim\\OneDrive\\Desktop\\SALVATORE MEGNA DATI PANEL.xlsx\"   # dataset ESG (mensile)\n",
    "\n",
    "\n",
    "# CONFIGURAZIONE ANALISI\n",
    "\n",
    "# Gruppi titolo \n",
    "USA_HIGH = [\"NEE\", \"XEL\", \"DUK\"]                # Utility/transizione (High ESG)\n",
    "USA_LOW  = [\"XOM\", \"CVX\", \"OXY\"]                # Oil & Gas (Low ESG)\n",
    "EU_HIGH  = [\"ENEL.MI\", \"IBE.MC\", \"EOAN.DE\"]     # Utility/transizione (High ESG)\n",
    "EU_LOW   = [\"TTE.PA\", \"BP.L\", \"ENI.MI\"]         # Oil & Gas (Low ESG)\n",
    "TICKERS_TUTTI = USA_HIGH + USA_LOW + EU_HIGH + EU_LOW\n",
    "\n",
    "# Ordine periodi coerente in tutte le tabelle\n",
    "PERIODI_ORDINATI = [\"pre_trump\", \"trump\", \"biden\"]\n",
    "\n",
    "# Mappatura ticker ESG -> ticker Yahoo Finance\n",
    "MAPPA_ESG2YF = {\n",
    "    \"NEE-US\":\"NEE\",\"XEL-US\":\"XEL\",\"DUK-US\":\"DUK\",\n",
    "    \"XOM-US\":\"XOM\",\"CVX-US\":\"CVX\",\"OXY-US\":\"OXY\",\n",
    "    \"ENEL-IT\":\"ENEL.MI\",\"IBE-ES\":\"IBE.MC\",\"EOAN-DE\":\"EOAN.DE\",\n",
    "    \"TTE-FR\":\"TTE.PA\",\"BP-GB\":\"BP.L\",\"ENI-IT\":\"ENI.MI\"\n",
    "}\n",
    "\n",
    "# Funzioni utilità per area e classe ESG\n",
    "def _area_di(ticker: str) -> str:\n",
    "    return \"USA\" if ticker in (USA_HIGH + USA_LOW) else \"EU\"\n",
    "\n",
    "def _classe_esg_di(ticker: str) -> str:\n",
    "    return \"High\" if ticker in (USA_HIGH + EU_HIGH) else \"Low\"\n",
    "\n",
    "\n",
    "# CARICAMENTO E PREPARAZIONE DATI\n",
    "\n",
    "def carica_prezzi_e_rendimenti(percorso_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Legge prezzi mensili (date, ticker, price) e calcola i rendimenti mensili per ticker (wide).\n",
    "    FIX duplicati: se nello stesso mese esistono più righe per un ticker, tiene SOLO l’ultima del mese.\n",
    "    Ritorna un DataFrame wide di rendimenti (index=date month-end, colonne=tickers).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(percorso_csv):\n",
    "        raise FileNotFoundError(f\"File prezzi non trovato: {percorso_csv}\")\n",
    "\n",
    "    df = pd.read_csv(percorso_csv)\n",
    "    richieste = {\"date\", \"ticker\", \"price\"}\n",
    "    if not richieste.issubset(df.columns):\n",
    "        raise ValueError(f\"Colonne richieste per prezzi: {richieste}. Trovate: {df.columns.tolist()}\")\n",
    "\n",
    "    # filtra i ticker del progetto\n",
    "    df = df[df[\"ticker\"].isin(TICKERS_TUTTI)].copy()\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Il file prezzi non contiene i ticker richiesti dal progetto.\")\n",
    "\n",
    "    # forza date a month-end e prendi l’ultima osservazione del mese per (ticker, mese)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.to_period(\"M\").dt.to_timestamp(\"M\")\n",
    "    df = (df.sort_values([\"ticker\", \"date\"])\n",
    "            .groupby([\"ticker\", \"date\"], as_index=False)[\"price\"]\n",
    "            .last())\n",
    "\n",
    "    # pivot e rendimenti mensili\n",
    "    prezzi_wide = df.pivot(index=\"date\", columns=\"ticker\", values=\"price\").sort_index()\n",
    "    r_titoli = prezzi_wide.pct_change().dropna(how=\"all\")\n",
    "\n",
    "    print(\">>> Controllo duplicati su date di r_titoli:\", int(r_titoli.index.duplicated().sum()))\n",
    "    return r_titoli\n",
    "\n",
    "\n",
    "def carica_benchmark(percorso_csv: str) -> tuple[pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Carica i rendimenti mensili dei benchmark di settore da file (già in % mensile).\n",
    "    Restituisce due Serie indicizzate a month-end: (bm_USA, bm_EU).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(percorso_csv):\n",
    "        raise FileNotFoundError(f\"File benchmark non trovato: {percorso_csv}\")\n",
    "\n",
    "    bm = pd.read_csv(percorso_csv)\n",
    "    richieste = {\"date\", \"bm_USA\", \"bm_EU\"}\n",
    "    if not richieste.issubset(bm.columns):\n",
    "        raise ValueError(f\"Colonne richieste per benchmark: {richieste}. Trovate: {bm.columns.tolist()}\")\n",
    "\n",
    "    bm[\"date\"] = pd.to_datetime(bm[\"date\"]).dt.to_period(\"M\").dt.to_timestamp(\"M\")\n",
    "    bm = bm.sort_values(\"date\").set_index(\"date\")\n",
    "\n",
    "    return bm[\"bm_USA\"].astype(float), bm[\"bm_EU\"].astype(float)\n",
    "\n",
    "\n",
    "def carica_esg_lag1(percorso_xlsx: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carica il dataset ESG, mappa i ticker a Yahoo, ordina per (ticker,data),\n",
    "    e costruisce i punteggi a lag 1 (mese precedente) per E, S, G e totale ESG.\n",
    "    Ritorna un DataFrame con colonne: ticker, date, E_lag1, S_lag1, G_lag1, ESG_lag1.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(percorso_xlsx):\n",
    "        raise FileNotFoundError(f\"File ESG non trovato: {percorso_xlsx}\")\n",
    "\n",
    "    esg = pd.read_excel(percorso_xlsx, sheet_name=0)\n",
    "\n",
    "    # parsing data (mm/yy) -> month-end\n",
    "    esg[\"date\"] = pd.to_datetime(esg[\"Date\"], format=\"%m/%y\").dt.to_period(\"M\").dt.to_timestamp(\"M\")\n",
    "    esg[\"ticker\"] = esg[\"Ticker\"].map(MAPPA_ESG2YF)\n",
    "\n",
    "    esg = esg.dropna(subset=[\"ticker\"]).sort_values([\"ticker\", \"date\"])\n",
    "\n",
    "    # lag mensile\n",
    "    esg[\"E_lag1\"]   = esg.groupby(\"ticker\")[\"ESG-E SCORE\"].shift(1)\n",
    "    esg[\"S_lag1\"]   = esg.groupby(\"ticker\")[\"ESG-S SCORE\"].shift(1)\n",
    "    esg[\"G_lag1\"]   = esg.groupby(\"ticker\")[\"ESG-G SCORE\"].shift(1)\n",
    "    esg[\"ESG_lag1\"] = esg.groupby(\"ticker\")[\"ESG TOT SCORE\"].shift(1)\n",
    "\n",
    "    esg = esg[[\"ticker\", \"date\", \"E_lag1\", \"S_lag1\", \"G_lag1\", \"ESG_lag1\"]].dropna()\n",
    "    return esg[esg[\"ticker\"].isin(TICKERS_TUTTI)]\n",
    "\n",
    "\n",
    "def costruisci_rendimenti_relativi(r_titoli: pd.DataFrame,\n",
    "                                   bm_usa: pd.Series,\n",
    "                                   bm_eu: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Costruisce i rendimenti relativi: r_rel = r_titolo - r_benchmark_area\n",
    "    dove l’area è 'USA' o 'EU' a seconda del ticker.\n",
    "    Restituisce un DataFrame long con: date, ticker, area, r_stock, r_sector, r_rel.\n",
    "    \"\"\"\n",
    "    # unisco i benchmark in una tabella (index = date)\n",
    "    bm = pd.DataFrame({\"USA\": bm_usa, \"EU\": bm_eu}).dropna(how=\"any\")\n",
    "\n",
    "    # allineo le date dei rendimenti dei titoli a quelle dei benchmark\n",
    "    r_titoli = r_titoli.loc[bm.index]\n",
    "\n",
    "    # formato “long”\n",
    "    lungo = r_titoli.stack().reset_index()\n",
    "    lungo.columns = [\"date\", \"ticker\", \"r_stock\"]\n",
    "    lungo[\"area\"] = lungo[\"ticker\"].map(_area_di)\n",
    "    lungo[\"r_sector\"] = lungo.apply(lambda r: bm.loc[r[\"date\"], r[\"area\"]], axis=1)\n",
    "    lungo[\"r_rel\"] = lungo[\"r_stock\"] - lungo[\"r_sector\"]\n",
    "\n",
    "    # sicurezza: date a month-end\n",
    "    lungo[\"date\"] = lungo[\"date\"].dt.to_period(\"M\").dt.to_timestamp(\"M\")\n",
    "    return lungo.dropna(subset=[\"r_rel\"])\n",
    "\n",
    "\n",
    "def aggiungi_colonne_periodo(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggiunge colonne:\n",
    "    - periodo (pre_trump, trump, biden) con ordine imposto\n",
    "    - area (USA/EU)\n",
    "    - esg_class (High/Low)\n",
    "    Rimuove eventuali righe fuori intervallo analizzato.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"periodo\"] = pd.Categorical(\n",
    "        np.select(\n",
    "            [\n",
    "                (df[\"date\"] >= pd.Timestamp(\"2013-01-01\")) & (df[\"date\"] <= pd.Timestamp(\"2016-12-31\")),\n",
    "                (df[\"date\"] >= pd.Timestamp(\"2017-01-01\")) & (df[\"date\"] <= pd.Timestamp(\"2020-12-31\")),\n",
    "                (df[\"date\"] >= pd.Timestamp(\"2021-01-01\")) & (df[\"date\"] <= pd.Timestamp(\"2024-12-31\")),\n",
    "            ],\n",
    "            PERIODI_ORDINATI,\n",
    "            default=\"out\"\n",
    "        ),\n",
    "        categories=PERIODI_ORDINATI,\n",
    "        ordered=True\n",
    "    )\n",
    "    df = df[df[\"periodo\"] != \"out\"]\n",
    "    df[\"area\"] = df[\"ticker\"].map(_area_di)\n",
    "    df[\"esg_class\"] = df[\"ticker\"].map(_classe_esg_di)\n",
    "    return df\n",
    "\n",
    "\n",
    "# LAYER A — TARGET A 12 MESI (IN AVANTI) E RANDOM FOREST\n",
    "\n",
    "def costruisci_target_12m_avanti(panel: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Costruisce il target a 12 mesi in avanti: somma dei 12 r_rel successivi.\n",
    "    Restituisce il panel con colonna 'r_rel_12m_fwd' e senza NaN su questa colonna.\n",
    "    \"\"\"\n",
    "    df = panel.sort_values([\"ticker\", \"date\"]).copy()\n",
    "    s = 0\n",
    "    for k in range(1, 13):\n",
    "        s += df.groupby(\"ticker\")[\"r_rel\"].shift(-k)\n",
    "    df[\"r_rel_12m_fwd\"] = s\n",
    "    return df.dropna(subset=[\"r_rel_12m_fwd\"])\n",
    "\n",
    "\n",
    "def modello_layer_a_target_12m(panel_12m: pd.DataFrame,\n",
    "                               features: list[str] | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Allena e valuta un Random Forest per periodo→area, con split temporale 80/20.\n",
    "    Restituisce tabella con R2_test, MAE_test e dimensioni campione per blocco.\n",
    "    \"\"\"\n",
    "    if features is None:\n",
    "        features = [\"E_lag1\", \"S_lag1\", \"G_lag1\", \"ESG_lag1\"]\n",
    "\n",
    "    righe = []\n",
    "    for periodo in PERIODI_ORDINATI:      # coerenza: prima periodo\n",
    "        for area in [\"USA\", \"EU\"]:        # poi area\n",
    "            d = panel_12m[(panel_12m[\"periodo\"] == periodo) & (panel_12m[\"area\"] == area)].copy()\n",
    "            if len(d) < 40:\n",
    "                continue\n",
    "\n",
    "            d = d.sort_values(\"date\")\n",
    "            split = int(len(d) * 0.8)     # train/test temporale\n",
    "\n",
    "            Xtr, Xte = d[features].iloc[:split], d[features].iloc[split:]\n",
    "            ytr, yte = d[\"r_rel_12m_fwd\"].iloc[:split], d[\"r_rel_12m_fwd\"].iloc[split:]\n",
    "\n",
    "            rf = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "            rf.fit(Xtr, ytr)\n",
    "            y_pred = rf.predict(Xte)\n",
    "\n",
    "            righe.append({\n",
    "                \"periodo\": periodo,\n",
    "                \"area\": area,\n",
    "                \"R2_test\": r2_score(yte, y_pred),\n",
    "                \"MAE_test\": mean_absolute_error(yte, y_pred),\n",
    "                \"n_total\": len(d),\n",
    "                \"n_train\": len(Xtr),\n",
    "                \"n_test\": len(Xte)\n",
    "            })\n",
    "\n",
    "    out = pd.DataFrame(righe).round(3)\n",
    "    if not out.empty:\n",
    "        out[\"periodo\"] = pd.Categorical(out[\"periodo\"], PERIODI_ORDINATI, ordered=True)\n",
    "        out = out.sort_values([\"periodo\", \"area\"])\n",
    "    return out\n",
    "\n",
    "\n",
    "# LAYER B — SHARPE AGGREGATO E BOOTSTRAP DELTA (HIGH−LOW)\n",
    "\n",
    "def sharpe_aggregato_per_gruppo(panel: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Per ogni (periodo × area × classe ESG) calcola:\n",
    "    - serie equal-weight dei r_rel dei titoli del gruppo (media trasversale)\n",
    "    - Sharpe annualizzato = (media/std) * sqrt(12)\n",
    "    Riporta anche media, deviazione standard e numero di mesi.\n",
    "    \"\"\"\n",
    "    righe = []\n",
    "    for (per, area, cls), g in panel.groupby([\"periodo\", \"area\", \"esg_class\"]):\n",
    "        serie = (g.pivot_table(index=\"date\", columns=\"ticker\", values=\"r_rel\")\n",
    "                 .mean(axis=1).dropna())\n",
    "        if serie.shape[0] < 12:\n",
    "            continue\n",
    "        mu, sd = serie.mean(), serie.std(ddof=1)\n",
    "        righe.append({\n",
    "            \"periodo\": per,\n",
    "            \"area\": area,\n",
    "            \"esg_class\": cls,\n",
    "            \"sharpe_agg\": (mu / sd) * np.sqrt(12) if sd > 0 else np.nan,\n",
    "            \"mean\": mu,\n",
    "            \"std\": sd,\n",
    "            \"n\": serie.shape[0]\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(righe).round(3)\n",
    "    if not out.empty:\n",
    "        out[\"periodo\"] = pd.Categorical(out[\"periodo\"], PERIODI_ORDINATI, ordered=True)\n",
    "        out = out.sort_values([\"periodo\", \"area\", \"esg_class\"])\n",
    "    return out\n",
    "\n",
    "\n",
    "def bootstrap_delta_sharpe(panel: pd.DataFrame,\n",
    "                           n_boot: int = 5000,\n",
    "                           seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Confronto High vs Low ESG per (periodo × area) sullo Sharpe aggregato:\n",
    "    - delta = Sharpe(High) − Sharpe(Low)\n",
    "    - intervallo di confidenza 95% e p-value bootstrap (resampling temporale)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    righe = []\n",
    "\n",
    "    for (per, area), g in panel.groupby([\"periodo\", \"area\"]):\n",
    "        high = (g[g[\"esg_class\"] == \"High\"]\n",
    "                .pivot_table(index=\"date\", columns=\"ticker\", values=\"r_rel\")\n",
    "                .mean(axis=1).dropna())\n",
    "        low  = (g[g[\"esg_class\"] == \"Low\"]\n",
    "                .pivot_table(index=\"date\", columns=\"ticker\", values=\"r_rel\")\n",
    "                .mean(axis=1).dropna())\n",
    "\n",
    "        idx_comuni = high.index.intersection(low.index)\n",
    "        if len(idx_comuni) < 12:\n",
    "            continue\n",
    "\n",
    "        h = high.loc[idx_comuni].values\n",
    "        l = low.loc[idx_comuni].values\n",
    "\n",
    "        def sharpe(x: np.ndarray) -> float:\n",
    "            sd = x.std(ddof=1)\n",
    "            return (x.mean() / sd) * np.sqrt(12) if sd > 0 else np.nan\n",
    "\n",
    "        delta = sharpe(h) - sharpe(l)\n",
    "\n",
    "        # bootstrap temporale (resampling con rimpiazzo sugli indici 0..T-1)\n",
    "        T = len(idx_comuni)\n",
    "        boots = []\n",
    "        for _ in range(n_boot):\n",
    "            b = rng.integers(0, T, T)\n",
    "            boots.append(sharpe(h[b]) - sharpe(l[b]))\n",
    "        boots = np.array(boots)\n",
    "\n",
    "        ci_lo, ci_hi = np.quantile(boots, [0.025, 0.975])\n",
    "        pval = (np.mean(boots >= abs(delta)) + np.mean(boots <= -abs(delta)))\n",
    "        pval = min(1.0, pval)\n",
    "\n",
    "        righe.append({\n",
    "            \"periodo\": per,\n",
    "            \"area\": area,\n",
    "            \"delta_sharpe_high_minus_low\": delta,\n",
    "            \"ci95_low\": ci_lo,\n",
    "            \"ci95_high\": ci_hi,\n",
    "            \"p_value\": pval,\n",
    "            \"n_months\": T\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(righe).round(3)\n",
    "    if not out.empty:\n",
    "        out[\"periodo\"] = pd.Categorical(out[\"periodo\"], PERIODI_ORDINATI, ordered=True)\n",
    "        out = out.sort_values([\"periodo\", \"area\"])\n",
    "    return out\n",
    "\n",
    "\n",
    "# PROGRAMMA PRINCIPALE\n",
    "\n",
    "def main() -> None:\n",
    "    print(\"=\" * 78)\n",
    "    print(\"ANALISI ESG ENERGY — avvio (Layer A 12M → Layer B)\")\n",
    "    print(\"=\" * 78)\n",
    "\n",
    "    # 1) Rendimenti mensili dei titoli, con fix duplicati\n",
    "    r_titoli = carica_prezzi_e_rendimenti(PRICES_CSV)\n",
    "\n",
    "    # 2) Rendimenti benchmark (USA/EU) da file\n",
    "    bm_usa, bm_eu = carica_benchmark(BENCH_CSV)\n",
    "\n",
    "    # 3) dataset base con rendimenti relativi\n",
    "    base_rel = costruisci_rendimenti_relativi(r_titoli, bm_usa, bm_eu)\n",
    "\n",
    "    # 4) Punteggi ESG (lag1) e arricchimento panel con periodo/area/classe\n",
    "    esg_lag = carica_esg_lag1(ESG_PANEL_XLSX)\n",
    "    panel = aggiungi_colonne_periodo(base_rel.merge(esg_lag, on=[\"ticker\", \"date\"], how=\"inner\"))\n",
    "\n",
    "    #  Anteprima pulita (senza r_rel) \n",
    "    colonne_preview = [\"date\",\"ticker\",\"area\",\"periodo\",\"esg_class\",\"E_lag1\",\"S_lag1\",\"G_lag1\",\"ESG_lag1\"]\n",
    "    print(\"\\n>>> Anteprima PANEL (senza r_rel):\")\n",
    "    print(panel[colonne_preview].head().to_string(index=False))\n",
    "\n",
    "    # Info dataset\n",
    "    print(\"\\nTickers nel panel:\", sorted(panel[\"ticker\"].unique()))\n",
    "    print(\"Date:\", panel[\"date\"].min().date(), \"→\", panel[\"date\"].max().date())\n",
    "    conteggi = (panel.groupby([\"periodo\",\"area\",\"esg_class\"])[\"ticker\"]\n",
    "                .count().rename(\"n_osservazioni\").reset_index())\n",
    "    conteggi[\"periodo\"] = pd.Categorical(conteggi[\"periodo\"], PERIODI_ORDINATI, ordered=True)\n",
    "    conteggi = conteggi.sort_values([\"periodo\",\"area\",\"esg_class\"])\n",
    "    print(\"\\nDistribuzione osservazioni (periodo → area → classe):\")\n",
    "    print(conteggi.to_string(index=False))\n",
    "\n",
    "    #  LAYER A \n",
    "    panel_12m = costruisci_target_12m_avanti(panel)\n",
    "    print(\"\\n=== TARGET 12M — Check (senza r_rel) ===\")\n",
    "    cols_chk = [\"ticker\",\"date\",\"r_rel_12m_fwd\",\"E_lag1\",\"S_lag1\",\"G_lag1\",\"ESG_lag1\",\"periodo\",\"area\",\"esg_class\"]\n",
    "    print(panel_12m[cols_chk].head().to_string(index=False))\n",
    "\n",
    "    metriche12m = modello_layer_a_target_12m(panel_12m)\n",
    "    print(\"\\n=== LAYER A (12M avanti) — METRICHE TEST (periodo → area) ===\")\n",
    "    cols_out = [\"periodo\",\"area\",\"R2_test\",\"MAE_test\",\"n_total\",\"n_train\",\"n_test\"]\n",
    "    print(metriche12m[cols_out].to_string(index=False) if not metriche12m.empty else \"Dati insufficienti.\")\n",
    "\n",
    "    # LAYER B \n",
    "    sharpe_gruppi = sharpe_aggregato_per_gruppo(panel)\n",
    "    print(\"\\n=== SHARPE RELATIVO — AGGREGATO per GRUPPO (periodo → area × classe) ===\")\n",
    "    print(sharpe_gruppi.to_string(index=False) if not sharpe_gruppi.empty else \"Dati insufficienti.\")\n",
    "\n",
    "    boot = bootstrap_delta_sharpe(panel)\n",
    "    print(\"\\n=== TEST BOOTSTRAP: Delta Sharpe (High - Low) (periodo → area) ===\")\n",
    "    print(boot.to_string(index=False) if not boot.empty else \"Dati insufficienti.\")\n",
    "\n",
    "    print(\"\\nFINE.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8547255-b763-4a8b-8be0-9d02311367d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
